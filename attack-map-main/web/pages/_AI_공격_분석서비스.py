# web/pages/3_AI_ê³µê²©_ë¶„ì„.py
import streamlit as st
import pandas as pd
import altair as alt
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import numpy as np

# ê³µìš© ëª¨ë“ˆ import
from ui_components import setup_page, display_sidebar, display_footer
from data_handler import load_events

# ë¨¸ì‹ ëŸ¬ë‹ ë° ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty: return df
    df_engineered = df.copy()
    if 'ts' in df_engineered.columns and pd.api.types.is_datetime64_any_dtype(df_engineered['ts']):
        df_engineered['hour'] = df_engineered['ts'].dt.hour
    else:
        df_engineered['hour'] = 0
    if 'label' in df_engineered.columns:
        le = LabelEncoder()
        df_engineered['label_encoded'] = le.fit_transform(df_engineered['label'])
    else:
        df_engineered['label_encoded'] = 0
    return df_engineered

@st.cache_data
def find_optimal_k(X_scaled):
    inertias = []
    k_range = range(2, 11)
    for k in k_range:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')
        kmeans.fit(X_scaled)
        inertias.append(kmeans.inertia_)
    try:
        deltas = np.diff(inertias, 2)
        optimal_k = k_range[np.argmax(deltas) + 1]
    except ValueError:
        optimal_k = 4
    elbow_df = pd.DataFrame({'K': k_range, 'Inertia': inertias})
    return optimal_k, elbow_df

@st.cache_data
def run_ml_analysis(df_engineered, features, optimal_k):
    X = df_engineered[features].copy()
    X.fillna(0, inplace=True)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init='auto')
    clusters = kmeans.fit_predict(X_scaled)
    pca = PCA(n_components=2, random_state=42)
    X_pca = pca.fit_transform(X_scaled)
    result_df = df_engineered.copy()
    result_df['cluster'] = clusters
    result_df['pca1'] = X_pca[:, 0]
    result_df['pca2'] = X_pca[:, 1]
    return result_df

# ë©”ì¸ ì‹¤í–‰ ë¡œì§
def main():
    setup_page("ğŸ¤–", "ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ê³µê²© ë¶„ì„")
    events_path = display_sidebar()
    df = load_events(str(events_path))

    st.markdown("KMeansë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì´ ê³µê²© ë°ì´í„°ì˜ íŠ¹ì§•ì„ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë§ì„ ì§„í–‰í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ ì‚¬ìš©í•˜ëŠ” íŠ¹ì§•ì€ ìœ„ë„, ê²½ë„, ì‹¬ê°ë„, ì‹œê°„, ê³µê²©ìœ í˜•ì˜ 5ê°€ì§€ì…ë‹ˆë‹¤.")
    st.markdown("ì´í›„ PCAë¥¼ í†µí•´ 5ê°€ì§€ íŠ¹ì§•ì„ 2ì°¨ì›ìœ¼ë¡œ ì••ì¶•í•˜ì—¬ ì£¼ì„±ë¶„ ì¶•1, ì£¼ì„±ë¶„ ì¶•2ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‹œê°í™”í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤. ì‚°ì ë„ ê·¸ë¦¼ ì•„ë˜ì— ê° í´ëŸ¬ìŠ¤í„°ë³„ íŠ¹ì§•ì´ ì •ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    st.markdown("---")
    
    if df.empty:
        st.warning("ë¶„ì„í•  ì´ë²¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 1. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ë° ë¶„ì„ ì‹¤í–‰
    df_engineered = feature_engineering(df)
    features_for_ml = ['lat', 'lon', 'severity', 'hour', 'label_encoded']
    X_scaled_for_k = StandardScaler().fit_transform(df_engineered[features_for_ml])
    optimal_k, elbow_df = find_optimal_k(X_scaled_for_k)
    result_df = run_ml_analysis(df_engineered, features_for_ml, optimal_k)
    
    st.subheader("ğŸ¤– PCA ë¶„ì„ ê²°ê³¼")
    st.info(f"ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ **{optimal_k}ê°œì˜ ê³ ìœ í•œ ê³µê²© íŒ¨í„´(ê·¸ë£¹)**ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.", icon="ğŸ’¡")
    
    # 2. ê³µê²© êµ°ì§‘ ì‹œê°í™”
    scatter_chart = alt.Chart(result_df).mark_circle(size=80).encode(
        x=alt.X('pca1:Q', title='ì£¼ì„±ë¶„ 1'),
        y=alt.Y('pca2:Q', title='ì£¼ì„±ë¶„ 2'),
        color=alt.Color('cluster:N', legend=alt.Legend(title="ê³µê²© ê·¸ë£¹")),
        tooltip=['ts', 'src_ip', 'country_code', 'label', 'severity', 'hour', 'cluster']
    ).properties(height=500).interactive()
    
    st.altair_chart(scatter_chart, use_container_width=True)
    st.markdown("---")

    st.subheader("ê·¸ë£¹ë³„ ê³µê²© íŒ¨í„´ í”„ë¡œíŒŒì¼ë§")
    
    # ê° ê·¸ë£¹ì— ëŒ€í•œ í†µê³„ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•´ ì»¬ëŸ¼ ëŒ€ì‹  expander ì‚¬ìš©
    for i in range(optimal_k):
        with st.expander(f"**ê·¸ë£¹ {i}** ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„", expanded= i == 0):
            cluster_df = result_df[result_df['cluster'] == i]
            
            st.metric(label=f"ê·¸ë£¹ {i}ì˜ ì´ ê³µê²© íšŸìˆ˜", value=f"{len(cluster_df)} ê±´")
            st.metric(label="í‰ê·  ê³µê²© ì‹¬ê°ë„", value=f"{cluster_df['severity'].mean():.2f}")

            st.markdown("---")

            # 2ë‹¨ ì»¬ëŸ¼ìœ¼ë¡œ í†µê³„ ì°¨íŠ¸ í‘œì‹œ
            col1, col2 = st.columns(2)

            with col1:
                st.markdown("##### ì£¼ìš” ê³µê²© êµ­ê°€ (Top 5)")
                top_countries = cluster_df['country_code'].value_counts().head(5).reset_index()
                top_countries.columns = ['country', 'count']
                
                country_chart = alt.Chart(top_countries).mark_bar().encode(
                    x=alt.X('count:Q', title='íšŸìˆ˜'),
                    y=alt.Y('country:N', title='êµ­ê°€', sort='-x'),
                    tooltip=['country', 'count']
                ).properties(height=200)
                st.altair_chart(country_chart, use_container_width=True)

            with col2:
                st.markdown("##### ì£¼ìš” ê³µê²© ìœ í˜• (Top 5)")
                top_labels = cluster_df['label'].value_counts().head(5).reset_index()
                top_labels.columns = ['label', 'count']

                label_chart = alt.Chart(top_labels).mark_bar().encode(
                    x=alt.X('count:Q', title='íšŸìˆ˜'),
                    y=alt.Y('label:N', title='ìœ í˜•', sort='-x'),
                    tooltip=['label', 'count']
                ).properties(height=200)
                st.altair_chart(label_chart, use_container_width=True)

    display_footer()

if __name__ == "__main__":
    main()